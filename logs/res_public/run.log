Namespace(exp_name='res_public', model='resnet')
ResNet18(
  (b1): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  )
  (b2): Sequential(
    (0): Residual(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (b3): Sequential(
    (0): Residual(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (b4): Sequential(
    (0): Residual(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (b5): Sequential(
    (0): Residual(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Residual(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (drop2): Dropout(p=0.5, inplace=False)
  (drop3): Dropout(p=0.5, inplace=False)
  (drop4): Dropout(p=0.5, inplace=False)
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (fc): Linear(in_features=512, out_features=2, bias=True)
)
Preparing data...
Using: cuda
Number of model parameters: 11.18M
Start to train...

Epoch 1 | Learning Rate is 0.000100
Epoch 1 | Mean train loss is 0.365319, Train acc is 87.034
Epoch 1 | Mean valid loss is 0.423958, valid acc is 78.289
Best valid acc is 78.289

Epoch 2 | Learning Rate is 0.000100
Epoch 2 | Mean train loss is 0.260057, Train acc is 88.713
Epoch 2 | Mean valid loss is 0.384586, valid acc is 78.289
Best valid acc is 78.289

Epoch 3 | Learning Rate is 0.000099
Epoch 3 | Mean train loss is 0.207867, Train acc is 91.604
Epoch 3 | Mean valid loss is 0.150015, valid acc is 92.763
Best valid acc is 92.763

Epoch 4 | Learning Rate is 0.000098
Epoch 4 | Mean train loss is 0.149636, Train acc is 94.123
Epoch 4 | Mean valid loss is 0.692616, valid acc is 67.105
Best valid acc is 92.763

Epoch 5 | Learning Rate is 0.000096
Epoch 5 | Mean train loss is 0.089926, Train acc is 96.455
Epoch 5 | Mean valid loss is 0.311457, valid acc is 90.789
Best valid acc is 92.763

Epoch 6 | Learning Rate is 0.000093
Epoch 6 | Mean train loss is 0.080136, Train acc is 97.108
Epoch 6 | Mean valid loss is 0.291769, valid acc is 89.474
Best valid acc is 92.763

Epoch 7 | Learning Rate is 0.000090
Epoch 7 | Mean train loss is 0.096562, Train acc is 95.989
Epoch 7 | Mean valid loss is 0.216375, valid acc is 90.132
Best valid acc is 92.763

Epoch 8 | Learning Rate is 0.000087
Epoch 8 | Mean train loss is 0.051195, Train acc is 98.134
Epoch 8 | Mean valid loss is 0.220363, valid acc is 92.105
Best valid acc is 92.763

Epoch 9 | Learning Rate is 0.000083
Epoch 9 | Mean train loss is 0.048164, Train acc is 98.228
Epoch 9 | Mean valid loss is 0.138016, valid acc is 93.421
Best valid acc is 93.421

Epoch 10 | Learning Rate is 0.000079
Epoch 10 | Mean train loss is 0.020965, Train acc is 99.067
Epoch 10 | Mean valid loss is 0.285972, valid acc is 93.421
Best valid acc is 93.421

Epoch 11 | Learning Rate is 0.000075
Epoch 11 | Mean train loss is 0.010733, Train acc is 100.000
Epoch 11 | Mean valid loss is 0.311823, valid acc is 92.763
Best valid acc is 93.421

Epoch 12 | Learning Rate is 0.000070
Epoch 12 | Mean train loss is 0.018515, Train acc is 99.254
Epoch 12 | Mean valid loss is 0.345345, valid acc is 92.763
Best valid acc is 93.421

Epoch 13 | Learning Rate is 0.000065
Epoch 13 | Mean train loss is 0.007844, Train acc is 99.720
Epoch 13 | Mean valid loss is 0.262849, valid acc is 92.763
Best valid acc is 93.421

Epoch 14 | Learning Rate is 0.000060
Epoch 14 | Mean train loss is 0.007403, Train acc is 99.813
Epoch 14 | Mean valid loss is 0.324547, valid acc is 93.421
Best valid acc is 93.421

Epoch 15 | Learning Rate is 0.000055
Epoch 15 | Mean train loss is 0.039387, Train acc is 98.694
Epoch 15 | Mean valid loss is 0.203068, valid acc is 92.763
Best valid acc is 93.421

Epoch 16 | Learning Rate is 0.000050
Epoch 16 | Mean train loss is 0.013418, Train acc is 99.813
Epoch 16 | Mean valid loss is 0.244419, valid acc is 90.132
Best valid acc is 93.421

Epoch 17 | Learning Rate is 0.000045
Epoch 17 | Mean train loss is 0.002606, Train acc is 100.000
Epoch 17 | Mean valid loss is 0.279087, valid acc is 92.763
Best valid acc is 93.421

Epoch 18 | Learning Rate is 0.000040
Epoch 18 | Mean train loss is 0.000959, Train acc is 100.000
Epoch 18 | Mean valid loss is 0.236977, valid acc is 92.105
Best valid acc is 93.421

Epoch 19 | Learning Rate is 0.000035
Epoch 19 | Mean train loss is 0.001590, Train acc is 99.907
Epoch 19 | Mean valid loss is 0.290246, valid acc is 92.105
Best valid acc is 93.421

Epoch 20 | Learning Rate is 0.000030
Epoch 20 | Mean train loss is 0.004867, Train acc is 99.907
Epoch 20 | Mean valid loss is 0.264358, valid acc is 92.105
Best valid acc is 93.421

Epoch 21 | Learning Rate is 0.000025
Epoch 21 | Mean train loss is 0.001066, Train acc is 100.000
Epoch 21 | Mean valid loss is 0.218508, valid acc is 91.447
Best valid acc is 93.421

Epoch 22 | Learning Rate is 0.000021
Epoch 22 | Mean train loss is 0.000552, Train acc is 100.000
Epoch 22 | Mean valid loss is 0.215876, valid acc is 93.421
Best valid acc is 93.421

Epoch 23 | Learning Rate is 0.000017
Epoch 23 | Mean train loss is 0.000452, Train acc is 100.000
Epoch 23 | Mean valid loss is 0.210389, valid acc is 92.105
Best valid acc is 93.421

Epoch 24 | Learning Rate is 0.000013
Epoch 24 | Mean train loss is 0.000383, Train acc is 100.000
Epoch 24 | Mean valid loss is 0.228727, valid acc is 91.447
Best valid acc is 93.421

Epoch 25 | Learning Rate is 0.000010
Epoch 25 | Mean train loss is 0.000358, Train acc is 100.000
Epoch 25 | Mean valid loss is 0.228432, valid acc is 92.105
Best valid acc is 93.421

Epoch 26 | Learning Rate is 0.000007
Epoch 26 | Mean train loss is 0.000356, Train acc is 100.000
Epoch 26 | Mean valid loss is 0.223793, valid acc is 93.421
Best valid acc is 93.421

Epoch 27 | Learning Rate is 0.000004
Epoch 27 | Mean train loss is 0.000324, Train acc is 100.000
Epoch 27 | Mean valid loss is 0.201032, valid acc is 93.421
Best valid acc is 93.421

Epoch 28 | Learning Rate is 0.000002
Epoch 28 | Mean train loss is 0.000258, Train acc is 100.000
Epoch 28 | Mean valid loss is 0.224894, valid acc is 92.763
Best valid acc is 93.421

Epoch 29 | Learning Rate is 0.000001
Epoch 29 | Mean train loss is 0.000315, Train acc is 100.000
Epoch 29 | Mean valid loss is 0.243818, valid acc is 92.763
Best valid acc is 93.421

Epoch 30 | Learning Rate is 0.000000
Epoch 30 | Mean train loss is 0.000356, Train acc is 100.000
Epoch 30 | Mean valid loss is 0.236314, valid acc is 91.447
Best valid acc is 93.421
Start to test...
Mean test loss is 0.499481, test acc is 90.064

Namespace(dataset='public', exp_name='exp_adam_3', model='resnet')
Start to test...
Mean test loss is 0.499481, test acc is 90.064
mAP(AP): 0.9761
Directly calculate precision and recall:
Precision: 0.9247311827956989
Recall: 0.9626865671641791
Set threshold to 0.915 and calculate precision and recall:
Precision: 0.9360902255639098
Recall: 0.9291044776119403
